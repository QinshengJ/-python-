## 数据集说明
- USPS 为较小规模的一个黑白图片集
- MNIST 为较大规模的一个黑白图片集
- mnist_m 为较大规模的一个彩色图片集，且带背景干扰

## 代码分支
### 10 分类（混合）
#### hybrid（有模型无日志；有关闭域自适应的对照模型）
- 强纠缠层超参：
   ```python
   n_qubits = 5 # 量子比特数量
   n_layers = 6 # 变分电路深度
   ```
- 提供了 10 分类 USPS-->MNIST 领域自适应经典量子混合神经网络  
- 所包含的训练好的模型的参数信息来自吴师兄的原文件（原文件包中并无训练日志），准确率大约为 0.88  

#### hybrid_mnist2mnistm（训练时间很长）
- 强纠缠层超参：
   ```python
   n_qubits = 5 # 量子比特数量
   n_layers = 6 # 变分电路深度
   ```
- 提供了 10 分类 MNIST-->mnist_m 领域自适应经典量子混合神经网络  
- 采用这种方法时，由于 MNIST、mnist_m 数据集均较大，需要非常长的训练时间
- 所包含的训练好的模型准确率在 0.76 左右
- 理论上也可以裁剪数据集大小，效果未知

#### hybrid_usps2mnistm（效果不佳）
- 强纠缠层超参：
   ```python
   n_qubits = 5 # 量子比特数量
   n_layers = 6 # 变分电路深度
   ```
- 10 分类 USPS-->mnist_m 领域自适应经典量子混合神经网络
- 100 epochs 训练后基本稳定在 0.3 的准确率，难以正式使用

### 2 分类（混合）
#### hybrid_binary（进行33轮后由于效果极佳而停止训练，有日志；有关闭域自适应的对照模型）
- 强纠缠层超参：
   ```python
   n_qubits = 2 # 量子比特数量
   n_layers = 2 # 变分电路深度
   ```
- 提供了 2 分类 USPS-->MNIST 领域自适应经典量子混合神经网络
- 所包含的训练好的模型准确率在 0.99 左右
- 可以在国盾 66 qubits 真实量子计算机上运行并得到较好效果

#### hybrid_binary_4layers（训练完成）
- 强纠缠层超参：
   ```python
   n_qubits = 2 # 量子比特数量
   n_layers = 4 # 变分电路深度
   ```
- 提供了 2 分类 USPS-->MNIST 领域自适应经典量子混合神经网络
- **不能**在国盾 66 qubits 真实量子计算机得到较好效果
- 可以在 IBM 物理机上运行并得到较好效果
- 考虑到 hybrid_binary 已经使用更简单的量子电路实现了极佳的效果，没有理由轻易使用该模型。然而，或许在该结构基础上支持彩色图片，会获得更高的准确率（当然，国盾平台下无法实际使用）。

#### hybrid_binary_rgb（训练完成；有关闭域自适应的对照模型）
- 强纠缠层超参：
   ```python
   n_qubits = 2 # 量子比特数量
   n_layers = 2 # 变分电路深度
   ```
- 提供了 2 分类 MNIST-->mnist_m 领域自适应经典量子混合神经网络
- 所包含的训练好的模型准确率在 0.88 左右
- 可以在国盾 66 qubits 真实量子计算机上运行并得到较好效果

### 4 分类（混合）
#### hybrid_quaternary_rgb（训练完成）
- 强纠缠层超参：
   ```python
   n_qubits = 4 # 量子比特数量
   n_layers = 3 # 变分电路深度
   ```
- 提供了 4 分类 MNIST-->mnist_m 领域自适应经典量子混合神经网络
- 似乎并不能在国盾 66 qubits 真实量子计算机上得到较好效果

#### hybrid_quaternary_2layers_rgb（训练完成）
- 强纠缠层超参：
   ```python
   n_qubits = 4 # 量子比特数量
   n_layers = 2 # 变分电路深度
   ```
- 提供了 4 分类 MNIST-->mnist_m 领域自适应经典量子混合神经网络
- 测试效果不佳，准确率在 0.47 左右

### 2 分类（全量子）
#### fully_quantum（进行36轮后由于效果极佳而停止训练，有日志；有关闭域自适应的对照模型）
- 提供了 2 分类 16x16 全振幅编码的全量子领域自适应（USPS-->MNIST）神经网络
- 所包含的训练好的模型准确率在 0.98 左右

#### fully_quantum_wuenc（搁置，未提供）
- 提供了 2 分类 16x16 辅助比特编码方式的全量子领域自适应（USPS-->MNIST）神经网络
- 效果不佳，暂时放弃，待辅助比特编码方式进化后可继续尝试

#### fully_quantum_rgb（训练完毕）
- 提供了 2 分类 3x16x16 全振幅编码的全量子领域自适应（MNIST-->mnist_m）神经网络
- 准确率 0.74

## 运行平台
### 总切换开关
可修改 quantum_net.py 切换内的信息切换运行框架为 Pennylane、Qiskit、GuoDun。  
```python
class QuantumBackend(Enum):
    Pennylane = 1
    GuoDun = 2
    Qiskit = 3


# 该变量指定当前的后端类型
current_quantum_backend = QuantumBackend.Pennylane
```

### Pennylane 框架指定设备
当切换到 Pennylane 框架时，请继续在 pennylane_feature_layer.py、pennylane_fc_layer.py 内修改 dev 变量选择所使用的设备  
Pennylane 可直接调用 IBM 量子云平台，但需要确保 pennylane-qiskit 包已安装。  
```python
dev = qml.device('lightning.qubit', wires=n_qubits)
# 以下代码使用 IBM 量子平台，请确保 pennylane-qiskit 包已安装
# simulator_mps 为 IBM 云端仿真设备，
# 可修改为其它设备如 ibmq_quito、ibmq_manila 等以使用真实量子设备
# dev = qml.device('qiskit.ibmq',
#                  wires=n_qubits,
#                  backend='simulator_mps',
#                  ibmqx_token="<请修改为您自己的 Token>")
```

### 注意事项
1. 建议不要使用云平台进行任何模型的训练，否则可能因为调用次数过多而造成积分耗尽、账号被封禁等问题。
2. IBM API 似乎会拒绝 CN 的 IP 直接访问，请配置好代理环境。
3. 不建议频繁登录 IBM 后台，尤其是不建议频繁使用不同的代理节点登录后台，否则极易造成账号被封禁等问题。
4. 代码内可能包含了有效的 Token，但请不要轻易使用，建议更换为自己的 Token。

## 环境准备
- PyTorch with CUDA support
- Pennylane
- Pennylane Qiskit Plugin （可选）
- Qiskit （可选）
- pyezQ （可选，国盾平台）


## 训练参数设置
修改 main.py 可切换是否开启领域自适应：
```python
domain_adaptation_enabled = True
```

## 运行代码
- 通过运行 `main.py` 进行训练
- 通过运行 `test.py` 可进行测试集的全量测试，并得到准确率
- 通过运行 `demo.py` 可进行可视化的效果展示

运行 `test.py` 和 `demo.py` 时，程序将扫描 models 文件夹下的 \*.pt 文件，并提示用户选择使用其中的具体某个模型：
> Found the following files of model parameters:
> 1. hybrid_best.pt
> 2. hybrid_current.pt
> 
> Choose a file (enter the corresponding number): 

请选择您需要使用的模型文件进行测试，通常为带有 best 的那个